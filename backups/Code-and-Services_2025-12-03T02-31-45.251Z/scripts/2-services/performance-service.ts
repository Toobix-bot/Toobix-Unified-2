/**
 * TOOBIX PERFORMANCE SERVICE v1.0
 *
 * Optimierung und Performance-Management fÃ¼r das gesamte System
 *
 * Features:
 * - ğŸš€ Advanced Multi-Level Caching (Memory, Disk, Distributed)
 * - âš–ï¸ Intelligent Load Balancing
 * - ğŸ“Š Performance Monitoring & Metrics
 * - ğŸ”§ Request Optimization & Compression
 * - ğŸ¯ Service Health Tracking
 * - â±ï¸ Response Time Analytics
 * - ğŸ”„ Cache Invalidation Strategies
 * - ğŸ“ˆ Auto-Scaling Recommendations
 */

import type { Serve } from 'bun';
import { writeFile, readFile, mkdir } from 'node:fs/promises';
import { existsSync } from 'node:fs';
import { join } from 'node:path';

// ========== TYPES ==========

interface CacheEntry {
  key: string;
  value: any;
  timestamp: number;
  ttl: number;
  hits: number;
  size: number;
  tags: string[];
}

interface CacheStats {
  totalEntries: number;
  totalHits: number;
  totalMisses: number;
  hitRate: number;
  totalSize: number;
  averageHitTime: number;
}

interface ServiceInstance {
  id: string;
  name: string;
  url: string;
  status: 'online' | 'offline' | 'degraded';
  currentLoad: number; // 0-1
  responseTime: number;
  requestCount: number;
  errorCount: number;
  lastHealthCheck: Date;
  capacity: number;
}

interface LoadBalancerStats {
  totalRequests: number;
  successfulRequests: number;
  failedRequests: number;
  averageResponseTime: number;
  activeInstances: number;
}

interface PerformanceMetrics {
  timestamp: Date;
  service: string;
  endpoint: string;
  responseTime: number;
  cacheHit: boolean;
  statusCode: number;
  requestSize: number;
  responseSize: number;
}

interface OptimizationRecommendation {
  type: 'cache' | 'load_balance' | 'scale' | 'optimize';
  priority: 'low' | 'medium' | 'high' | 'critical';
  service: string;
  description: string;
  impact: string;
  action: string;
}

// ========== MULTI-LEVEL CACHE ==========

class MultiLevelCache {
  private memoryCache: Map<string, CacheEntry> = new Map();
  private diskCachePath: string = join(process.cwd(), '.cache', 'performance');
  private stats: CacheStats = {
    totalEntries: 0,
    totalHits: 0,
    totalMisses: 0,
    hitRate: 0,
    totalSize: 0,
    averageHitTime: 0
  };

  constructor() {
    this.initDiskCache();
    this.startCacheCleanup();
  }

  private async initDiskCache() {
    if (!existsSync(this.diskCachePath)) {
      await mkdir(this.diskCachePath, { recursive: true });
    }
  }

  private getCacheKey(method: string, url: string, body?: any): string {
    const bodyHash = body ? JSON.stringify(body) : '';
    return `${method}:${url}:${bodyHash}`;
  }

  private calculateSize(value: any): number {
    return JSON.stringify(value).length;
  }

  async get(key: string): Promise<any | null> {
    const startTime = Date.now();

    // L1: Memory Cache
    const memoryEntry = this.memoryCache.get(key);
    if (memoryEntry) {
      if (Date.now() - memoryEntry.timestamp < memoryEntry.ttl) {
        memoryEntry.hits++;
        this.stats.totalHits++;
        const hitTime = Date.now() - startTime;
        this.updateAverageHitTime(hitTime);
        return memoryEntry.value;
      } else {
        this.memoryCache.delete(key);
      }
    }

    // L2: Disk Cache
    try {
      const diskPath = join(this.diskCachePath, `${Buffer.from(key).toString('base64')}.json`);
      if (existsSync(diskPath)) {
        const diskData = await readFile(diskPath, 'utf-8');
        const diskEntry: CacheEntry = JSON.parse(diskData);

        if (Date.now() - diskEntry.timestamp < diskEntry.ttl) {
          // Promote to memory cache
          this.memoryCache.set(key, diskEntry);
          diskEntry.hits++;
          this.stats.totalHits++;
          const hitTime = Date.now() - startTime;
          this.updateAverageHitTime(hitTime);
          return diskEntry.value;
        }
      }
    } catch (error) {
      // Disk cache miss or error
    }

    this.stats.totalMisses++;
    return null;
  }

  async set(key: string, value: any, ttl: number = 60000, tags: string[] = []): Promise<void> {
    const size = this.calculateSize(value);
    const entry: CacheEntry = {
      key,
      value,
      timestamp: Date.now(),
      ttl,
      hits: 0,
      size,
      tags
    };

    // Store in memory cache
    this.memoryCache.set(key, entry);
    this.stats.totalEntries = this.memoryCache.size;
    this.stats.totalSize += size;

    // Store in disk cache for persistence
    try {
      const diskPath = join(this.diskCachePath, `${Buffer.from(key).toString('base64')}.json`);
      await writeFile(diskPath, JSON.stringify(entry), 'utf-8');
    } catch (error) {
      console.error('Disk cache write error:', error);
    }

    // Memory management
    if (this.memoryCache.size > 1000) {
      this.evictLRU();
    }
  }

  private evictLRU(): void {
    // Find least recently used entry
    let lruKey: string | null = null;
    let lruTimestamp = Date.now();

    for (const [key, entry] of this.memoryCache.entries()) {
      if (entry.timestamp < lruTimestamp) {
        lruTimestamp = entry.timestamp;
        lruKey = key;
      }
    }

    if (lruKey) {
      const entry = this.memoryCache.get(lruKey);
      if (entry) {
        this.stats.totalSize -= entry.size;
      }
      this.memoryCache.delete(lruKey);
    }
  }

  async invalidate(pattern: string): Promise<number> {
    let count = 0;
    const keysToDelete: string[] = [];

    for (const [key] of this.memoryCache.entries()) {
      if (key.includes(pattern)) {
        keysToDelete.push(key);
        count++;
      }
    }

    for (const key of keysToDelete) {
      const entry = this.memoryCache.get(key);
      if (entry) {
        this.stats.totalSize -= entry.size;
      }
      this.memoryCache.delete(key);
    }

    this.stats.totalEntries = this.memoryCache.size;
    return count;
  }

  async invalidateByTags(tags: string[]): Promise<number> {
    let count = 0;
    const keysToDelete: string[] = [];

    for (const [key, entry] of this.memoryCache.entries()) {
      if (entry.tags.some(tag => tags.includes(tag))) {
        keysToDelete.push(key);
        count++;
      }
    }

    for (const key of keysToDelete) {
      const entry = this.memoryCache.get(key);
      if (entry) {
        this.stats.totalSize -= entry.size;
      }
      this.memoryCache.delete(key);
    }

    this.stats.totalEntries = this.memoryCache.size;
    return count;
  }

  clear(): void {
    this.memoryCache.clear();
    this.stats.totalEntries = 0;
    this.stats.totalSize = 0;
  }

  getStats(): CacheStats {
    const total = this.stats.totalHits + this.stats.totalMisses;
    this.stats.hitRate = total > 0 ? (this.stats.totalHits / total) * 100 : 0;
    return { ...this.stats };
  }

  private updateAverageHitTime(hitTime: number): void {
    if (this.stats.totalHits === 1) {
      this.stats.averageHitTime = hitTime;
    } else {
      this.stats.averageHitTime =
        (this.stats.averageHitTime * (this.stats.totalHits - 1) + hitTime) / this.stats.totalHits;
    }
  }

  private startCacheCleanup(): void {
    // Cleanup expired entries every 5 minutes
    setInterval(() => {
      const now = Date.now();
      const keysToDelete: string[] = [];

      for (const [key, entry] of this.memoryCache.entries()) {
        if (now - entry.timestamp > entry.ttl) {
          keysToDelete.push(key);
        }
      }

      for (const key of keysToDelete) {
        const entry = this.memoryCache.get(key);
        if (entry) {
          this.stats.totalSize -= entry.size;
        }
        this.memoryCache.delete(key);
      }

      this.stats.totalEntries = this.memoryCache.size;
    }, 300000);
  }

  getTopEntries(limit: number = 10): CacheEntry[] {
    const entries = Array.from(this.memoryCache.values());
    return entries
      .sort((a, b) => b.hits - a.hits)
      .slice(0, limit);
  }
}

// ========== LOAD BALANCER ==========

class LoadBalancer {
  private instances: Map<string, ServiceInstance[]> = new Map();
  private stats: LoadBalancerStats = {
    totalRequests: 0,
    successfulRequests: 0,
    failedRequests: 0,
    averageResponseTime: 0,
    activeInstances: 0
  };
  private algorithm: 'round-robin' | 'least-connections' | 'weighted' = 'least-connections';
  private roundRobinCounters: Map<string, number> = new Map();

  registerInstance(service: string, instance: ServiceInstance): void {
    if (!this.instances.has(service)) {
      this.instances.set(service, []);
    }
    this.instances.get(service)!.push(instance);
    this.updateActiveInstancesCount();
  }

  unregisterInstance(service: string, instanceId: string): void {
    const instances = this.instances.get(service);
    if (instances) {
      const filtered = instances.filter(i => i.id !== instanceId);
      this.instances.set(service, filtered);
      this.updateActiveInstancesCount();
    }
  }

  async selectInstance(service: string): Promise<ServiceInstance | null> {
    const instances = this.instances.get(service);
    if (!instances || instances.length === 0) {
      return null;
    }

    const healthyInstances = instances.filter(i => i.status === 'online');
    if (healthyInstances.length === 0) {
      return null;
    }

    switch (this.algorithm) {
      case 'round-robin':
        return this.selectRoundRobin(service, healthyInstances);
      case 'least-connections':
        return this.selectLeastConnections(healthyInstances);
      case 'weighted':
        return this.selectWeighted(healthyInstances);
      default:
        return healthyInstances[0];
    }
  }

  private selectRoundRobin(service: string, instances: ServiceInstance[]): ServiceInstance {
    const counter = this.roundRobinCounters.get(service) || 0;
    const selected = instances[counter % instances.length];
    this.roundRobinCounters.set(service, counter + 1);
    return selected;
  }

  private selectLeastConnections(instances: ServiceInstance[]): ServiceInstance {
    return instances.reduce((least, current) =>
      current.currentLoad < least.currentLoad ? current : least
    );
  }

  private selectWeighted(instances: ServiceInstance[]): ServiceInstance {
    // Weight based on capacity and current load
    const weights = instances.map(i => {
      const availableCapacity = i.capacity - i.currentLoad;
      const healthScore = i.status === 'online' ? 1 : 0.5;
      const responseScore = i.responseTime > 0 ? 1000 / i.responseTime : 1;
      return availableCapacity * healthScore * responseScore;
    });

    const totalWeight = weights.reduce((sum, w) => sum + w, 0);
    let random = Math.random() * totalWeight;

    for (let i = 0; i < instances.length; i++) {
      random -= weights[i];
      if (random <= 0) {
        return instances[i];
      }
    }

    return instances[0];
  }

  recordRequest(success: boolean, responseTime: number): void {
    this.stats.totalRequests++;
    if (success) {
      this.stats.successfulRequests++;
    } else {
      this.stats.failedRequests++;
    }

    this.stats.averageResponseTime =
      (this.stats.averageResponseTime * (this.stats.totalRequests - 1) + responseTime) / this.stats.totalRequests;
  }

  getStats(): LoadBalancerStats {
    return { ...this.stats };
  }

  getAllInstances(): Map<string, ServiceInstance[]> {
    return new Map(this.instances);
  }

  private updateActiveInstancesCount(): void {
    let count = 0;
    for (const instances of this.instances.values()) {
      count += instances.filter(i => i.status === 'online').length;
    }
    this.stats.activeInstances = count;
  }

  setAlgorithm(algorithm: 'round-robin' | 'least-connections' | 'weighted'): void {
    this.algorithm = algorithm;
  }

  getAlgorithm(): string {
    return this.algorithm;
  }
}

// ========== PERFORMANCE MONITOR ==========

class PerformanceMonitor {
  private metrics: PerformanceMetrics[] = [];
  private maxMetrics: number = 10000;

  recordMetric(metric: PerformanceMetrics): void {
    this.metrics.push(metric);
    if (this.metrics.length > this.maxMetrics) {
      this.metrics.shift();
    }
  }

  getMetrics(filters?: {
    service?: string;
    endpoint?: string;
    since?: Date;
  }): PerformanceMetrics[] {
    let filtered = [...this.metrics];

    if (filters?.service) {
      filtered = filtered.filter(m => m.service === filters.service);
    }
    if (filters?.endpoint) {
      filtered = filtered.filter(m => m.endpoint === filters.endpoint);
    }
    if (filters?.since) {
      filtered = filtered.filter(m => m.timestamp >= filters.since);
    }

    return filtered;
  }

  getAverageResponseTime(service?: string): number {
    const relevantMetrics = service
      ? this.metrics.filter(m => m.service === service)
      : this.metrics;

    if (relevantMetrics.length === 0) return 0;

    const total = relevantMetrics.reduce((sum, m) => sum + m.responseTime, 0);
    return total / relevantMetrics.length;
  }

  getCacheHitRate(service?: string): number {
    const relevantMetrics = service
      ? this.metrics.filter(m => m.service === service)
      : this.metrics;

    if (relevantMetrics.length === 0) return 0;

    const hits = relevantMetrics.filter(m => m.cacheHit).length;
    return (hits / relevantMetrics.length) * 100;
  }

  getErrorRate(service?: string): number {
    const relevantMetrics = service
      ? this.metrics.filter(m => m.service === service)
      : this.metrics;

    if (relevantMetrics.length === 0) return 0;

    const errors = relevantMetrics.filter(m => m.statusCode >= 400).length;
    return (errors / relevantMetrics.length) * 100;
  }

  getSlowestEndpoints(limit: number = 10): Array<{endpoint: string, avgTime: number}> {
    const endpointTimes = new Map<string, number[]>();

    for (const metric of this.metrics) {
      const key = `${metric.service}:${metric.endpoint}`;
      if (!endpointTimes.has(key)) {
        endpointTimes.set(key, []);
      }
      endpointTimes.get(key)!.push(metric.responseTime);
    }

    const averages = Array.from(endpointTimes.entries()).map(([endpoint, times]) => ({
      endpoint,
      avgTime: times.reduce((sum, t) => sum + t, 0) / times.length
    }));

    return averages.sort((a, b) => b.avgTime - a.avgTime).slice(0, limit);
  }

  clear(): void {
    this.metrics = [];
  }
}

// ========== OPTIMIZATION ENGINE ==========

class OptimizationEngine {
  private cache: MultiLevelCache;
  private loadBalancer: LoadBalancer;
  private monitor: PerformanceMonitor;

  constructor(cache: MultiLevelCache, loadBalancer: LoadBalancer, monitor: PerformanceMonitor) {
    this.cache = cache;
    this.loadBalancer = loadBalancer;
    this.monitor = monitor;
  }

  generateRecommendations(): OptimizationRecommendation[] {
    const recommendations: OptimizationRecommendation[] = [];

    // Cache recommendations
    const cacheStats = this.cache.getStats();
    if (cacheStats.hitRate < 30) {
      recommendations.push({
        type: 'cache',
        priority: 'high',
        service: 'global',
        description: 'Low cache hit rate detected',
        impact: 'Increased response times and service load',
        action: 'Review caching strategy and increase TTL for stable endpoints'
      });
    }

    // Load balancing recommendations
    const lbStats = this.loadBalancer.getStats();
    if (lbStats.failedRequests > lbStats.successfulRequests * 0.1) {
      recommendations.push({
        type: 'load_balance',
        priority: 'critical',
        service: 'global',
        description: 'High failure rate detected',
        impact: 'User experience degradation',
        action: 'Check service health and add more instances'
      });
    }

    // Response time recommendations
    const slowEndpoints = this.monitor.getSlowestEndpoints(5);
    for (const slow of slowEndpoints) {
      if (slow.avgTime > 1000) {
        recommendations.push({
          type: 'optimize',
          priority: slow.avgTime > 3000 ? 'critical' : 'high',
          service: slow.endpoint.split(':')[0],
          description: `Slow endpoint detected: ${slow.endpoint}`,
          impact: `Average response time: ${slow.avgTime.toFixed(0)}ms`,
          action: 'Optimize endpoint logic, add caching, or consider async processing'
        });
      }
    }

    // Scaling recommendations
    if (lbStats.activeInstances < 2 && lbStats.totalRequests > 1000) {
      recommendations.push({
        type: 'scale',
        priority: 'medium',
        service: 'global',
        description: 'Low number of service instances under high load',
        impact: 'Potential bottleneck during traffic spikes',
        action: 'Consider horizontal scaling by adding more service instances'
      });
    }

    return recommendations.sort((a, b) => {
      const priorityOrder = { critical: 4, high: 3, medium: 2, low: 1 };
      return priorityOrder[b.priority] - priorityOrder[a.priority];
    });
  }

  getHealthScore(): number {
    const cacheStats = this.cache.getStats();
    const lbStats = this.loadBalancer.getStats();
    const avgResponseTime = this.monitor.getAverageResponseTime();
    const errorRate = this.monitor.getErrorRate();

    // Calculate weighted health score (0-100)
    const cacheScore = Math.min(cacheStats.hitRate, 100);
    const successScore = lbStats.totalRequests > 0
      ? (lbStats.successfulRequests / lbStats.totalRequests) * 100
      : 100;
    const responseScore = avgResponseTime > 0
      ? Math.max(0, 100 - (avgResponseTime / 10))
      : 100;
    const errorScore = Math.max(0, 100 - errorRate * 2);

    return (cacheScore * 0.2 + successScore * 0.3 + responseScore * 0.3 + errorScore * 0.2);
  }
}

// ========== PERFORMANCE SERVICE ==========

class PerformanceService {
  private cache: MultiLevelCache;
  private loadBalancer: LoadBalancer;
  private monitor: PerformanceMonitor;
  private optimizer: OptimizationEngine;

  constructor() {
    this.cache = new MultiLevelCache();
    this.loadBalancer = new LoadBalancer();
    this.monitor = new PerformanceMonitor();
    this.optimizer = new OptimizationEngine(this.cache, this.loadBalancer, this.monitor);
  }

  serve(): Serve {
    return {
      port: 8934,
      fetch: async (req) => {
        const url = new URL(req.url);

        // Health check
        if (url.pathname === '/health') {
          return Response.json({
            status: 'ok',
            service: 'performance-service',
            port: 8934,
            healthScore: this.optimizer.getHealthScore(),
            cacheStats: this.cache.getStats(),
            loadBalancerStats: this.loadBalancer.getStats()
          });
        }

        // Cache operations
        if (url.pathname === '/cache/get' && req.method === 'POST') {
          const { key } = await req.json() as any;
          const value = await this.cache.get(key);
          return Response.json({
            success: value !== null,
            value,
            cached: value !== null
          });
        }

        if (url.pathname === '/cache/set' && req.method === 'POST') {
          const { key, value, ttl, tags } = await req.json() as any;
          await this.cache.set(key, value, ttl, tags);
          return Response.json({ success: true });
        }

        if (url.pathname === '/cache/invalidate' && req.method === 'POST') {
          const { pattern } = await req.json() as any;
          const count = await this.cache.invalidate(pattern);
          return Response.json({ success: true, invalidated: count });
        }

        if (url.pathname === '/cache/invalidate-tags' && req.method === 'POST') {
          const { tags } = await req.json() as any;
          const count = await this.cache.invalidateByTags(tags);
          return Response.json({ success: true, invalidated: count });
        }

        if (url.pathname === '/cache/stats' && req.method === 'GET') {
          return Response.json({
            success: true,
            stats: this.cache.getStats(),
            topEntries: this.cache.getTopEntries(10)
          });
        }

        if (url.pathname === '/cache/clear' && req.method === 'DELETE') {
          this.cache.clear();
          return Response.json({ success: true });
        }

        // Load balancer operations
        if (url.pathname === '/load-balancer/register' && req.method === 'POST') {
          const { service, instance } = await req.json() as any;
          this.loadBalancer.registerInstance(service, instance);
          return Response.json({ success: true });
        }

        if (url.pathname === '/load-balancer/unregister' && req.method === 'POST') {
          const { service, instanceId } = await req.json() as any;
          this.loadBalancer.unregisterInstance(service, instanceId);
          return Response.json({ success: true });
        }

        if (url.pathname === '/load-balancer/select' && req.method === 'POST') {
          const { service } = await req.json() as any;
          const instance = await this.loadBalancer.selectInstance(service);
          return Response.json({
            success: instance !== null,
            instance
          });
        }

        if (url.pathname === '/load-balancer/stats' && req.method === 'GET') {
          return Response.json({
            success: true,
            stats: this.loadBalancer.getStats(),
            algorithm: this.loadBalancer.getAlgorithm(),
            instances: Object.fromEntries(this.loadBalancer.getAllInstances())
          });
        }

        if (url.pathname === '/load-balancer/algorithm' && req.method === 'POST') {
          const { algorithm } = await req.json() as any;
          this.loadBalancer.setAlgorithm(algorithm);
          return Response.json({ success: true, algorithm });
        }

        // Performance monitoring
        if (url.pathname === '/monitor/record' && req.method === 'POST') {
          const metric = await req.json() as PerformanceMetrics;
          metric.timestamp = new Date();
          this.monitor.recordMetric(metric);
          return Response.json({ success: true });
        }

        if (url.pathname === '/monitor/metrics' && req.method === 'GET') {
          const service = url.searchParams.get('service') || undefined;
          const endpoint = url.searchParams.get('endpoint') || undefined;
          const since = url.searchParams.get('since')
            ? new Date(url.searchParams.get('since')!)
            : undefined;

          const metrics = this.monitor.getMetrics({ service, endpoint, since });
          return Response.json({
            success: true,
            metrics,
            count: metrics.length
          });
        }

        if (url.pathname === '/monitor/stats' && req.method === 'GET') {
          const service = url.searchParams.get('service') || undefined;
          return Response.json({
            success: true,
            averageResponseTime: this.monitor.getAverageResponseTime(service),
            cacheHitRate: this.monitor.getCacheHitRate(service),
            errorRate: this.monitor.getErrorRate(service),
            slowestEndpoints: this.monitor.getSlowestEndpoints(10)
          });
        }

        // Optimization
        if (url.pathname === '/optimize/recommendations' && req.method === 'GET') {
          return Response.json({
            success: true,
            recommendations: this.optimizer.generateRecommendations(),
            healthScore: this.optimizer.getHealthScore()
          });
        }

        if (url.pathname === '/optimize/health-score' && req.method === 'GET') {
          return Response.json({
            success: true,
            healthScore: this.optimizer.getHealthScore()
          });
        }

        // Default: API documentation
        return Response.json({
          service: 'Toobix Performance Service',
          version: '1.0',
          endpoints: {
            'GET /health': 'Service health check',
            'POST /cache/get': 'Get cached value',
            'POST /cache/set': 'Set cached value',
            'POST /cache/invalidate': 'Invalidate by pattern',
            'POST /cache/invalidate-tags': 'Invalidate by tags',
            'GET /cache/stats': 'Cache statistics',
            'DELETE /cache/clear': 'Clear all cache',
            'POST /load-balancer/register': 'Register service instance',
            'POST /load-balancer/unregister': 'Unregister instance',
            'POST /load-balancer/select': 'Select best instance',
            'GET /load-balancer/stats': 'Load balancer stats',
            'POST /load-balancer/algorithm': 'Set LB algorithm',
            'POST /monitor/record': 'Record performance metric',
            'GET /monitor/metrics': 'Get metrics (with filters)',
            'GET /monitor/stats': 'Performance statistics',
            'GET /optimize/recommendations': 'Get optimization recommendations',
            'GET /optimize/health-score': 'Overall system health score'
          },
          features: [
            'Multi-level caching (Memory + Disk)',
            'Intelligent load balancing (Round-robin, Least-connections, Weighted)',
            'Performance monitoring and analytics',
            'Automatic optimization recommendations',
            'Cache invalidation by pattern or tags',
            'Response time tracking',
            'Error rate monitoring',
            'System health scoring'
          ]
        });
      }
    };
  }
}

// ========== START SERVER ==========

const service = new PerformanceService();

console.log(`
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                    â•‘
â•‘           ğŸš€ TOOBIX PERFORMANCE SERVICE v1.0                      â•‘
â•‘                                                                    â•‘
â•‘  Features:                                                        â•‘
â•‘  âœ… Multi-Level Caching (Memory + Disk)                           â•‘
â•‘  âœ… Intelligent Load Balancing                                    â•‘
â•‘  âœ… Performance Monitoring                                        â•‘
â•‘  âœ… Optimization Recommendations                                  â•‘
â•‘  âœ… Cache Invalidation Strategies                                 â•‘
â•‘  âœ… Response Time Analytics                                       â•‘
â•‘  âœ… System Health Scoring                                         â•‘
â•‘                                                                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸš€ Performance Service running on http://localhost:8934

ğŸ“Š CACHE OPERATIONS:
   POST   /cache/get              - Get cached value
   POST   /cache/set              - Set cached value (with TTL & tags)
   POST   /cache/invalidate       - Invalidate by pattern
   POST   /cache/invalidate-tags  - Invalidate by tags
   GET    /cache/stats            - Cache statistics
   DELETE /cache/clear            - Clear all cache

âš–ï¸  LOAD BALANCER:
   POST   /load-balancer/register    - Register service instance
   POST   /load-balancer/unregister  - Unregister instance
   POST   /load-balancer/select      - Select best instance
   GET    /load-balancer/stats       - Stats & instances
   POST   /load-balancer/algorithm   - Set algorithm (round-robin, least-connections, weighted)

ğŸ“ˆ MONITORING:
   POST   /monitor/record   - Record performance metric
   GET    /monitor/metrics  - Get metrics (filterable)
   GET    /monitor/stats    - Performance statistics

ğŸ”§ OPTIMIZATION:
   GET    /optimize/recommendations  - Get optimization recommendations
   GET    /optimize/health-score     - Overall system health (0-100)

ğŸ’¡ ALGORITHMS:
   - Round-Robin: Equal distribution
   - Least-Connections: Route to least loaded
   - Weighted: Smart routing based on capacity, health, response time

ğŸ¯ System ready for high-performance operations!
`);

export default service.serve();
